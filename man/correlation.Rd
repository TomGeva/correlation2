% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/correlation.R
\name{correlation}
\alias{correlation}
\title{Correlation Analysis}
\usage{
correlation(
  data,
  data2 = NULL,
  select = NULL,
  select2 = NULL,
  rename = NULL,
  method = "pearson",
  p_adjust = "holm",
  ci = 0.95,
  bayesian = FALSE,
  bayesian_prior = "medium",
  bayesian_ci_method = "hdi",
  bayesian_test = c("pd", "rope", "bf"),
  redundant = FALSE,
  include_factors = FALSE,
  partial = FALSE,
  partial_bayesian = FALSE,
  multilevel = FALSE,
  ranktransform = FALSE,
  winsorize = FALSE,
  verbose = TRUE,
  standardize_names = getOption("easystats.standardize_names", FALSE),
  ...
)
}
\arguments{
\item{data}{A data frame.}

\item{data2}{An optional data frame. If specified, all pair-wise correlations
between the variables in \code{data} and \code{data2} will be computed.}

\item{select, select2}{(Ignored if \code{data2} is specified.) Optional names
of variables that should be selected for correlation. Instead of providing
the data frames with those variables that should be correlated, \code{data}
can be a data frame and \code{select} and \code{select2} are (quoted) names
of variables (columns) in \code{data}. \code{correlation()} will then
compute the correlation between \code{data[select]} and
\code{data[select2]}. If only \code{select} is specified, all pairwise
correlations between the \code{select} variables will be computed. This is
a "pipe-friendly" alternative way of using \code{correlation()} (see
'Examples').}

\item{rename}{In case you wish to change the names of the variables in
the output, these arguments can be used to specify these alternative names.
Note that the number of names should be equal to the number of columns
selected. Ignored if \code{data2} is specified.}

\item{method}{A character string indicating which correlation coefficient is
to be used for the test. \cr Possible Values: \code{"pearson"} (default),
\code{"kendall"}, \code{"spearman"}, \code{"biserial"}, \code{"point-biserial"}, \code{"rankbiserial"},
\code{"polychoric"}, \code{"tetrachoric"}, \code{"biweight"}, \code{"distance"}, \code{"percentage"}
(for percentage bend correlation), \code{"blomqvist"} (for Blomqvist's
coefficient), \code{"hoeffding"} (for Hoeffding's D), \code{"gamma"}, \code{"gaussian"}
(for Gaussian Rank correlation), \code{"shepherd"} (for Shepherd's Pi correlation).
\cr (polychoric when ordinal factors involved, tetrachoric when dichotomous
factors involved, point-biserial if one dichotomous and one continuous and
pearson otherwise). See below the \strong{details} section for a description of
these indices.}

\item{p_adjust}{Correction method for frequentist correlations. Can be one of
\code{"holm"} (default), \code{"hochberg"}, \code{"hommel"},
\code{"bonferroni"}, \code{"BH"}, \code{"BY"}, \code{"fdr"},
\code{"somers"} or \code{"none"}. See
\code{\link[stats:p.adjust]{stats::p.adjust()}} for further details.}

\item{ci}{Confidence/Credible Interval level. If \code{"default"}, then it is
set to \code{0.95} (\verb{95\%} CI).}

\item{bayesian}{If \code{TRUE}, will run the correlations under a Bayesian
framework.}

\item{redundant}{Should the data include redundant rows (where each given
correlation is repeated two times).}

\item{verbose}{Toggle warnings.}

\item{standardize_names}{This option can be set to \code{TRUE} to run
\code{\link[insight:standardize_names]{insight::standardize_names()}} on the output to get standardized column
names. This option can also be set globally by running
\code{options(easystats.standardize_names = TRUE)}.}

\item{...}{Optional arguments:
\itemize{
\item \code{data} A data frame (when \code{x} and/or \code{y} are not vectors).
\item Arguments dependent on \code{method} being:
\itemize{
\item \code{"kendall"}:
\itemize{
\item \code{tau_type} = \code{"b"}
\item \code{direction} = \code{"row"} (used when \code{tau_type} = \code{"a"})
}
\item \code{"percentage"}:
\itemize{
\item \code{beta} = \code{0.2}
}
\item \code{"bayes"}:
\itemize{
\item \code{bayesian_prior} = "medium"
\item \code{bayesian_ci_method} = "hdi"
\item \code{bayesian_test} = \code{c("pd", "rope", "bf")}
}
}
}}
}
\value{
A correlation object that can be displayed using the \code{print}, \code{summary} or
\code{table} methods.

\subsection{Multiple tests correction}{
The \code{p_adjust} argument can be used to adjust p-values for multiple
comparisons. All adjustment methods available in \code{p.adjust} function
\code{stats} package are supported.
}
}
\description{
Performs a correlation analysis.
You can easily visualize the result using \code{\link[=visualisation_recipe.easycormatrix]{plot()}}
(see examples \href{https://easystats.github.io/correlation/reference/visualisation_recipe.easycormatrix.html#ref-examples}{\strong{here}}).
}
\details{
\subsection{Partial Correlation}{
\strong{Partial correlations} are estimated as the correlation between two
variables after adjusting for the (linear) effect of one or more other
variable. The correlation test is then run after having partialized the
dataset, independently from it. In other words, it considers partialization
as an independent step generating a different dataset, rather than belonging
to the same model. This is why some discrepancies are to be expected for the
t- and p-values, CIs, BFs etc (but \emph{not} the correlation coefficient)
compared to other implementations (e.g., \code{ppcor}). (The size of these
discrepancies depends on the number of covariates partialled-out and the
strength of the linear association between all variables.) Such partial
correlations can be represented as Gaussian Graphical Models (GGM), an
increasingly popular tool in psychology. A GGM traditionally include a set of
variables depicted as circles ("nodes"), and a set of lines that visualize
relationships between them, which thickness represents the strength of
association (see Bhushan et al., 2019).

\strong{Multilevel correlations} are a special case of partial correlations where
the variable to be adjusted for is a factor and is included as a random
effect in a mixed model (note that the remaining continuous variables of the
dataset will still be included as fixed effects, similarly to regular partial
correlations). The model is a random intercept model, i.e. the multilevel
correlation is adjusted for \code{(1 | groupfactor)}.That said, there is an
important difference between using \code{cor_test()} and \code{correlation()}: If you
set \code{multilevel=TRUE} in \code{correlation()} but \code{partial} is set to \code{FALSE} (as
per default), then a back-transformation from partial to non-partial
correlation will be attempted (through \code{\link[=pcor_to_cor]{pcor_to_cor()}}).
However, this is not possible when using \code{cor_test()} so that if you set
\code{multilevel=TRUE} in it, the resulting correlations are partial one. Note
that for Bayesian multilevel correlations, if \code{partial = FALSE}, the back
transformation will also recompute \emph{p}-values based on the new \emph{r} scores,
and will drop the Bayes factors (as they are not relevant anymore). To keep
Bayesian scores, set \code{partial = TRUE}.
}

\subsection{Notes}{
Kendall and Spearman correlations when \code{bayesian=TRUE}: These are technically
Pearson Bayesian correlations of rank transformed data, rather than pure
Bayesian rank correlations (which have different priors).
}
}
\examples{
\dontshow{if (requireNamespace("poorman", quietly = TRUE) && requireNamespace("psych", quietly = TRUE)) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}

library(correlation)
library(poorman)

results <- correlation(iris)

results
summary(results)
summary(results, redundant = TRUE)

# pipe-friendly usage with  grouped dataframes from {dplyr} package
iris \%>\%
  correlation(select = "Petal.Width", select2 = "Sepal.Length")

# Grouped dataframe
# grouped correlations
iris \%>\%
  group_by(Species) \%>\%
  correlation()

# selecting specific variables for correlation
mtcars \%>\%
  group_by(am) \%>\%
  correlation(
    select = c("cyl", "wt"),
    select2 = c("hp")
  )

# supplying custom variable names
correlation(anscombe, select = c("x1", "x2"), rename = c("var1", "var2"))

# automatic selection of correlation method
correlation(mtcars[-2], method = "auto")
\dontshow{\}) # examplesIf}
}
\references{
\itemize{
\item Boudt, K., Cornelissen, J., & Croux, C. (2012). The Gaussian rank
correlation estimator: robustness properties. Statistics and Computing,
22(2), 471-483.
\item Bhushan, N., Mohnert, F., Sloot, D., Jans, L., Albers, C., & Steg, L.
(2019). Using a Gaussian graphical model to explore relationships between
items and variables in environmental psychology research. Frontiers in
psychology, 10, 1050.
\item Bishara, A. J., & Hittner, J. B. (2017). Confidence intervals for
correlations when data are not normal. Behavior research methods, 49(1),
294-309.
\item Fieller, E. C., Hartley, H. O., & Pearson, E. S. (1957). Tests for
rank correlation coefficients. I. Biometrika, 44(3/4), 470-481.
\item Langfelder, P., & Horvath, S. (2012). Fast R functions for robust
correlations and hierarchical clustering. Journal of statistical software,
46(11).
\item Blomqvist, N. (1950). On a measure of dependence between two random
variables,Annals of Mathematical Statistics,21, 593â€“600
\item Somers, R. H. (1962). A new asymmetric measure of association for
ordinal variables. American Sociological Review. 27 (6).
}
}
